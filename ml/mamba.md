Chris Fregly ‚ÄúAI Systems Performance Engineering‚Äù book 

<https://artint.info/3e/html/ArtInt3e.html>

<https://habr.com/ru/companies/piter/articles/1001790/> –ö–∞–∫ –≤ Netflix –º–∞—Å—à—Ç–∞–±–∏—Ä—É—é—Ç –ø–æ—Å—Ç–æ–±—É—á–µ–Ω–∏–µ LLM

<https://philipkiely.com/>  Inference Engineering book  
<https://www.youtube.com/watch?v=l0BdmevNhuc> Inference for ML

<https://www.amazon.com/Production-Ready-Deep-Learning-Practical-Deploying-ebook/dp/B0FXT9WW4K>
Practical Deep Learning Deployment: A Hands-On Guide with PyTorch, ONNX, and FastAPI. Adrian Devlin

<https://www.amazon.com/dp/1778042724/> The Hundred-Page Language Models Book: hands-on with PyTorch (The Hundred-Page Books)

<https://www.amazon.com/dp/1836200072> LLM Engineer's Handbook: Master the art of engineering large language models from concept to production

<https://maxhalford.github.io/blog/online-active-learning-river-databutton/>  Online Active Learning
 
 <https://github.com/roboticcam/machine-learning-notes> ML Learning Notes

 https://www.youtube.com/playlist?list=PLgPbN3w-ia_PeT1_c5jiLW3RJdR7853b9

<https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/>  

https://www.youtube.com/watch?v=IBJUt9JPKHk    Building resilient ML Engineering skills

https://github.com/stas00/  Stat Beckman 2 books: ml-engineering and the-art-of-debugging  
https://stasosphere.com/machine-learning/  

https://deeplearningwithpython.io/chapters/

https://github.com/Dyakonov/MLDM_BOOK   ML book

https://www.amazon.com/dp/1633436586/ Deep Learning with PyTorch

https://habr.com/ru/articles/804605/ ML algos

https://habr.com/ru/articles/1002298/

## Reinforcement learning 
https://habr.com/ru/articles/991622/

https://habr.com/ru/articles/1002298/

https://rlhfbook.com/  Reinforcement learning human feedback

## ONNX book
https://www.amazon.com/Ultimate-ONNX-Deep-Learning-Optimization/dp/9349887207/ 

1. Foundations of Machine Learning
https://cs.nyu.edu/~mohri/mlbook/

2. Understanding Deep Learning
https://udlbook.github.io/udlbook/

3. Introduction to Machine Learning Systems
http://mlsysbook.ai/assets/downloads/Machine-Learning-Systems.pdf -- wrong?
https://mlsysbook.ai/book/assets/downloads/Machine-Learning-Systems.pdf
 

4. Algorithms for ML
https://algorithmsbook.com

5. Deep Learning
http://deeplearningbook.org

6. Reinforcement Learning
https://andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf

7. Distributional Reinforcement Learning
https://direct.mit.edu/books/oa-monograph-pdf/2111075/book_9780262374026.pdf

8. Multi Agent Reinforcement Learning
https://marl-book.com

9. Agents in the Long Game of AI
https://direct.mit.edu/books/oa-monograph-pdf/2471103/book_9780262380355.pdf

10. Fairness and Machine Learning
https://fairmlbook.org

11. Probabilistic Machine Learning

  Part 1 : https://probml.github.io/pml-book/book1.html
  Part 2 : https://probml.github.io/pml-book/book2.html

 
Chris Bishop (all 3 books)
https://www.bishopbook.com

https://habr.com/ru/companies/yandex_praktikum/articles/986742/ –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–∫—Å—Ç–∞–º–∏: –ø–æ–¥–±–æ—Ä–∫–∞ –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –∫—É—Ä—Å–æ–≤ –∏ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤

https://www.youtube.com/c/joshstarmer

https://habr.com/ru/companies/bothub/articles/984648/ Loss functions

https://habr.com/ru/articles/984248/ –≥–∞–π–¥ –ø–æ —ç–∫–æ—Å–∏—Å—Ç–µ–º–µ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π

https://simonwillison.net/2025/Dec/31/the-year-in-llms/

https://www.youtube.com/playlist?list=PL0beoaW5rFR9oQg96Wu0NVsUZZpFbTzK9


https://mltechniques.com/product/ebook-state-of-the-art-in-genai-llms-creative-projects-with-solutions/ BOOK!

https://www.coursera.org/learn/deep-learning-reinforcement-learning

https://habr.com/ru/articles/983768/ Self-supervising learning

https://habr.com/ru/companies/selectel/articles/978482/ ML resources

https://leanpub.com/TOBoML2 The Orange Book of Machine Learning - Green edition

https://mltechniques.com/product/ebook-state-of-the-art-in-genai-llms-creative-projects-with-solutions/


https://arpitbhayani.me/blogs/qkv-matrices/

https://news.ycombinator.com/item?id=46523887


https://pixelbank.dev/ Leetcode for ML

 –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ç–µ–æ—Ä–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏
https://habr.com/ru/companies/wunderfund/articles/978786/

https://mlsysbook.ai/tinytorch/intro.html

https://arpitbhayani.me/blogs/qkv-matrices

https://habr.com/ru/articles/975468/ Model Quantization

https://habr.com/ru/articles/976576/

https://habr.com/ru/articles/972178/ –¢–æ–ø –≤–æ–ø—Ä–æ—Å–æ–≤ —Å NLP —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π: —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –∏ –≤–Ω–∏–º–∞–Ω–∏–µ –¥–æ –º–∞–ª–µ–π—à–∏—Ö –¥–µ—Ç–∞–ª–µ–π

https://www.dailydoseofds.com/

https://blog.dailydoseofds.com/p/7-categorical-data-encoding-techniques-cd2

https://github.com/Saivineeth147/awesome-llm-resources

https://habr.com/ru/companies/kryptonite/articles/961128/

https://arxiv.org/abs/2511.18538

https://github.com/harvard-edge/cs249r_book

https://www.mlsysbook.ai/assets/downloads/Machine-Learning-Systems.pdf

https://github.com/chiphuyen/aie-book

https://www.mlsysbook.ai/

https://github.com/rasbt/LLMs-from-scratch  Sebastian Rashka. Build LLM From Scratch

https://github.com/EthicalML/awesome-production-machine-learning/

   https://huggingface.co/learn/llm-course/chapter1

https://www.youtube.com/watch?v=681kv_x12u0

https://www.youtube.com/@vladimirnechaev4332

https://www.sergeynikolenko.ru/courses

https://www.lotas.ai/erdos  IDE for ML

https://www.reddit.com/r/MachineLearning/comments/1p4qdf3/d_what_are_the_best_machine_learning_phd_thesis/

https://habr.com/ru/articles/964438/ Linear regression and ML

https://www.skills.google/paths/183  Free cource from Google


1. LLM Introduction: http://lnkd.in/dMqbaZdK
2. LLMs from Scratch: http://lnkd.in/dYYwEhYy
3. Agentic AI Overview (Stanford): http://lnkd.in/dArmMt2i
4. Building and Evaluating Agents: http://lnkd.in/dBWd2W8u
5. Building Effective Agents: http://lnkd.in/dHfdebqw
6. Building Agents with MCP: http://lnkd.in/dXuNHrRJ
7. Building an Agent from Scratch: http://lnkd.in/da3ANw3w
8. Philo Agents: http://lnkd.in/dq-BfZE5
9. 
https://github.com/mohamedrxo/simplegrad

https://www.gilesthomas.com/2025/10/llm-from-scratch-20-starting-training-cross-entropy-loss

https://github.com/Mathews-Tom/Agentic-Design-Patterns

https://stepik.org/course/231306/promo

https://habr.com/ru/articles/951428/ –ß—Ç–æ —Ç–∞–∫–æ–µ AI-–∞–≥–µ–Ω—Ç –∏ –∏–∑ –∫–∞–∫–∏—Ö –æ—Å–Ω–æ–≤–Ω—ã—Ö —á–∞—Å—Ç–µ–π –æ–Ω —Å–æ—Å—Ç–æ–∏—Ç

https://habr.com/ru/articles/951390/ AI-–¥–≤–∏–∂–∫–∏ –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ Knowledge Distillation, GAN, Reinforcement learning

https://huggingface.co/learn

https://ma-lab-berkeley.github.io/deep-representation-learning-book/ 

### Reinforcement learning

https://www.understandingai.org/p/reinforcement-learning-explained

https://descent-visualisers.netlify.app/


https://habr.com/ru/articles/979394/

https://habr.com/ru/articles/956890/

https://www.youtube.com/watch?v=q9972BRoXzQ

https://habr.com/ru/articles/919556/

https://habr.com/ru/articles/958062/

https://habr.com/ru/companies/otus/articles/951412/ Q-learning

https://arxiv.org/pdf/1905.03375  Embarrassingly Shallow Autoencoders for Sparse Data

Free book:
https://www.manning.com/books/grokking-ai-algorithms-second-edition

## Casual Inference

https://matheusfacure.github.io/python-causality-handbook/landing-page.html

https://www.dailydoseofds.com/a-crash-course-on-causality-part-1


### Book
https://www.manning.com/books/deep-learning-with-python-third-edition 

 

### Book with code: Understanding Deep Learning 
https://udlbook.github.io/udlbook/

Book:
https://www.dataschool.io/master-machine-learning-book-preview/

###  Sebastian Rashka

https://sebastianraschka.com/

https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch01/#table-of-contents

https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch02/

https://habr.com/ru/articles/926160/  Russian translation of sebastianraschka.com

https://habr.com/ru/articles/964658/

https://habr.com/ru/articles/958880/

https://sebastianraschka.com/notebooks/ml-notebooks/

###  Book: Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems 3rd Edition

https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1098125975/ 

### Book: https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/copy.html

### Book: Forecasting: Principles and Practice, the Pythonic Way
https://otexts.com/fpppy

### Book: Information Theory, Inference, and Learning Algorithms. David J.C. MacKay
https://www.inference.org.uk/itprnn/book.pdf


–û—Ç –ø—Ä–æ–º—Ç–æ–≤ –∫ –∞–≥–µ–Ω—Ç–∞–º: –∫–∞–∫ –º—ã –¥–æ—à–ª–∏ –¥–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤, —á—Ç–æ LLM —É–º–µ—é—Ç —É–∂–µ —Å–µ–π—á–∞—Å –∏ —á—Ç–æ –Ω–∞—Å –∂–¥—ë—Ç –≤ 2027 –≥–æ–¥—É
https://habr.com/ru/companies/netologyru/articles/926776/

–ê–Ω—Ç–æ–Ω –ë–æ–π—Ü–µ–≤
https://www.youtube.com/@%D0%90%D0%BD%D1%82%D0%BE%D0%BD%D0%91%D0%BE%D0%B9%D1%86%D0%B5%D0%B2-%D1%8C9%D0%BE/videos

https://pypi.org/project/category-encoders

https://github.com/Dyakonov/DL

https://habr.com/ru/companies/pgk/articles/921596/ –ü—Ä–æ–∫–∞—á–∞—Ç—å—Å—è –≤ data science: –±–ª–æ–≥–∏ –∏ –∫–∞–Ω–∞–ª—ã

https://habr.com/ru/articles/926398/  ML interview preparation

https://www.youtube.com/watch?v=pdNYw6qwuNc 
What Are Neural Networks Even Doing? (Manifold Hypothesis)

https://dongou.tech/ai/dongou/ai-by-hand-%E2%9C%8D%EF%B8%8F-with-prof-tom-yeh-for-ai-professionals/

https://habr.com/ru/articles/918188/ –ö–∞–∫ —É—Å—Ç—Ä–æ–µ–Ω–æ –≥–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π

https://github.com/gavinkhung/machine-learning-visualized   ML visualized

https://habr.com/ru/articles/918438/ –§—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ ML/DL

https://habr.com/ru/articles/955636/ –¢–æ–ø –≤–æ–ø—Ä–æ—Å–æ–≤ —Å Data Science —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π

https://habr.com/ru/articles/926398/

https://habr.com/ru/articles/926160/
 
https://datasecrets.ru/articles

### https://franknielsen.github.io/Books/CuratedBookLists.html

https://habr.com/ru/articles/917664/ –æ—Å–Ω–æ–≤–æ–ø–æ–ª–∞–≥–∞—é—â–∏—Ö —Å—Ç–∞—Ç–µ–π –º–∏—Ä–∞ ML

### Self-attention implementation

https://eli.thegreenplace.net/2025/notes-on-implementing-attention/

## PyTorch

https://habr.com/ru/companies/otus/articles/975328/

https://www.iamtk.co/mastering-pytorch-from-linear-regression-to-computer-vision

https://www.clcoding.com/2024/10/deep-learning-with-pytorch-image.html 

https://news.ycombinator.com/item?id=44276476 I have reimplemented Stable Diffusion 3.5 from scratch in pure PyTorch (github.com/yousef-rafat)

 

https://github.com/ageron/handson-ml3



https://machine-learning-with-python.readthedocs.io/

https://lux-api.readthedocs.io/en/latest/index.html

Feature selection
https://ikromshi.com/2025/12/30/feature-selection-primer.html

https://eli.thegreenplace.net/2025/notes-on-implementing-attention/

https://eli.thegreenplace.net/2025/convolutions-polynomials-and-flipped-kernels/

https://news.ycombinator.com/item?id=44048306

https://habr.com/ru/companies/yandex_praktikum/articles/901432/

https://www.kaggle.com/discussions/getting-started/390402

## AI Chip startups

Cerebras Systems

Tenstorrent

SiMa.ai  

https://groq.com/ 

Lightmatter


### Ads clicks prediction

https://github.com/alirezadir/Machine-Learning-Interviews/blob/main/src/MLSD/mlsd-ads-ranking.md

### ML

https://github.com/HandsOnLLM/Hands-On-Large-Language-Models

https://news.ycombinator.com/item?id=43586073

https://habr.com/ru/articles/895332/ Bayes

https://habr.com/ru/companies/alfa/articles/895002/ uplift

https://habr.com/ru/companies/wunderfund/articles/894100/



https://arxiv.org/abs/2206.13446 Pen and Paper Exercises in Machine Learning

https://riverml.xyz/latest/ Online machine learning in Python

https://www.kdnuggets.com/10-github-repositories-to-master-machine-learning

https://github.com/Coder-World04/Data-and-ML-Projects-

https://habr.com/ru/articles/795251/ –¢–∏–ø–∏—á–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞. –ß–∞—Å—Ç—å 2. –ê –µ—Å—Ç—å –ª–∏ —Ç—Ä–µ–Ω–¥?

https://habr.com/ru/articles/795785/ 

https://habr.com/ru/articles/897946/ Error backpropagation

https://eli.thegreenplace.net/2025/reproducing-word2vec-with-jax/

https://habr.com/ru/companies/yadro/articles/896362/  Convolution –°–≤–µ—Ä—Ç–∫–∞ 

https://eli.thegreenplace.net/2024/ml-in-go-with-a-python-sidecar/

https://news.ycombinator.com/item?id=45110311 The maths you need to start understanding LLMs

### Probabilistic programming with NumPy powered by JAX for autograd and JIT compilation to GPU/TPU/CPU.
https://news.ycombinator.com/item?id=42156126    
https://num.pyro.ai/en/stable/   
https://github.com/pyro-ppl/numpyro    


1 ‚Üí Understanding Machine Learning
Theory meets algorithms.
Foundations explained clearly.
https://lnkd.in/dBME-P8q

2 ‚Üí Mathematics for ML
Linear algebra to calculus.
Build mathematical intuition.
https://lnkd.in/diK8E9N4

3 ‚Üí Mathematical Analysis
ML algorithms dissected.
Theory behind the code.
https://lnkd.in/dUBcRTUT

4 ‚Üí Deep Learning Principles
Neural networks demystified.
Physics meets AI.
https://lnkd.in/dkrCCqBM

5 ‚Üí ML with Networks
Neurons to backpropagation.
Practical neural network guide.
https://lnkd.in/dxujdJTM

6 ‚Üí Deep Learning Graphs
Graph neural networks explained.
Modern architectures covered.
https://lnkd.in/d3-_cZVy

7 ‚Üí Algorithmic ML Aspects
Complexity and optimization.
Advanced algorithm theory.
https://lnkd.in/drs_5znT

8 ‚Üí Probability Theory
Statistical foundations covered.
Examples and applications.
https://lnkd.in/dbDN7kyi

9 ‚Üí Elementary Probability
Beginner friendly approach.
Real world applications.
https://lnkd.in/dTMg54Ez

10 ‚Üí Advanced Data Analysis
Statistical learning methods.
Production level insights.
https://lnkd.in/dvSmYrtc


### Feature store
https://asrathore08.medium.com/feature-store-architecture-1324eff5a573

https://github.com/alteryx/featuretools Feature Engineering

### Comp vision

https://pbr-book.org/4ed/contents

https://habr.com/ru/articles/908168/

### Mamba
https://habr.com/ru/articles/786278/

https://habr.com/ru/articles/925416/


https://bernsteinbear.com/blog/simple-search/   Search 

### Multimodal LLM
https://arxiv.org/abs/2306.13549

Multimodal deep learning
https://arxiv.org/abs/2301.04856 

–°–æ–∑–¥–∞–Ω–∏–µ —É–º–Ω—ã—Ö AI-–∞–≥–µ–Ω—Ç–æ–≤: –ø–æ–ª–Ω—ã–π –∫—É—Ä—Å –ø–æ LangGraph –æ—Ç –ê –¥–æ –Ø. –ß–∞—Å—Ç—å 2. –î–∏–∞–ª–æ–≥–æ–≤—ã–µ –∞–≥–µ–Ω—Ç—ã: –ø–∞–º—è—Ç—å, —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç
https://habr.com/ru/companies/amvera/articles/948000/

### AIC (Akaike Information Criterion)  BIC ( Bayesian information criterion )
```
What is AIC and BIC? How these helps in ML Model Selection? 
The AIC can be used to select between the additive and multiplicative Holt-Winters models.
 Bayesian information criterion (BIC) (Stone, 1979) is another criteria for model selection
that measures the trade-off between model fit and complexity of the model.
A lower AIC or BIC value indicates a better fit.

AIC criterion often risk choosing too large a model, whereas BIC often risk choosing too small a model.
In modelling, there's always a risk of either under-fitting, for small n or over-fitting for large n.

Have you chosen the best model?

You may want to check AIC and BIC.
Let's explore what they are and how they can help in finding the optimal ARIMA model üßµüëá
AIC and BIC are both model selection criteria used to compare and rank different models.
They help you choose the best model for your data by evaluating
the trade-off between the fit of the model and its complexity.

1Ô∏è‚É£ AIC (Akaike Information Criterion):
It is used to evaluate the quality of a model by penalizing the number of parameters in the model.
The AIC score is calculated as the negative log-likelihood of the observed data, a
djusted by the number of parameters in the model.
The model with the lowest AIC score is generally considered to be the best model for the given data.
‚≠ê This score is a good balance between the fit of the model and its complexity,
making it a popular choice for model selection.

2Ô∏è‚É£ BIC (Bayesian Information Criterion):
It's similar to AIC, but it penalizes the number of parameters in the model more heavily.
BIC score is calculated as the negative log-likelihood of the observed data,
adjusted by the number of parameters in the model and the sample size.
The BIC score is intended to balance the fit of the model to the data with the complexity of the model.
‚≠ê It's often used when the sample size is large, and you want to avoid overfitting.
So, when choosing between models, you can use either AIC or BIC to help you find the best one.
```
MLFlow https://habr.com/ru/companies/pgk/articles/904078/


Here are 11 channels worth your time:
üî∏ Andrej Karpathy: from fundamentals to deep dives
https://lnkd.in/gcyMKQJB

üî∏ AI Coffee Break with Letitia: bite-sized ML concepts for your coffee breaks
https://lnkd.in/gE73wXbE

üî∏ Umar Jamil: builds ML + LLM techniques from scratch
https://lnkd.in/gmbrMj7D

üî∏ Simon Oz: low-level ML, excellent for fundamentals
https://lnkd.in/gNDkAm7M

üî∏ Art of Saience: break into the AI field without the hype
https://lnkd.in/gF3ypnTP

üî∏ 3blue1brown: the OG of visual explanations
https://lnkd.in/gByiG2By

üî∏ GPU Mode: deep dives into GPU architecture + ML workloads
https://lnkd.in/gR_tJ-f9

üî∏ AI Jason: beautifully explained AI experiments + design
https://lnkd.in/gCkyPvUw

üî∏ Yannic Kilcher: research papers explained without losing depth
https://lnkd.in/gACCpvhS

üî∏ Artem Kirsanov: neuroscience + ML with stunning visuals
https://lnkd.in/gUF-_J83

üî∏ Aleksa Gordiƒá: practical AI code walkthroughs
https://lnkd.in/gf_TAZkK


üî∏ Bonus: 
Master the basics here: https://lnkd.in/gTQyc_fi


s? ‚úÖ ‚Ä¢ The new MCP standard? ‚úÖ

‚û°Ô∏è LLM Course
üîóhttps://lnkd.in/gZuAHUSj

‚û°Ô∏è MCP Course
üîóhttps://lnkd.in/gxpFMHyZ

‚û°Ô∏è AI Agents Course
üîóhttps://lnkd.in/gHVhfa_c

‚û°Ô∏è Deep RL Course
üîóhttps://lnkd.in/gsrxQHH3

‚û°Ô∏è Robotics Course
üîóhttps://lnkd.in/g6fW7t4i

‚û°Ô∏è smol Course
üîóhttps://lnkd.in/gh6EyCAW

‚û°Ô∏è Computer Vision Course
üîóhttps://lnkd.in/gBwa8X9h

‚û°Ô∏è Audio Course
üîóhttps://lnkd.in/gWy5uiwr

‚û°Ô∏è Open-source AI Cookbook
üîóhttps://lnkd.in/ghT8c_cD


Books and Papers
Current

* Large Language Models: A Deep Dive: Bridging Theory and Practice
    * Uday Kamath, Kevin Keenan, Garrett Somers, and Sarah Sorenson
    * August 20, 2024
    * https://link.springer.com/book/10.1007/978-3-031-65647-7

Future

* Books
    * How Large Language Models Work
        * Edward Raff, Drew Farris, and Stella Biderman for Booz Allen Hamilton
        * June 2025
        * https://www.manning.com/books/how-large-language-models-work
    * Large Vision-Language Models: Pre-training, Prompting, and Applications
        * Kaiyang Zhou, Ziwei Liu, and Peng Gao
        * August 31, 2025
        * https://link.springer.com/book/10.1007/978-3-031-94969-2 
    * Domain-Specific Small Language Models
        * Guglielmo Iozzia
        * December, 2025
        * https://www.manning.com/books/domain-specific-small-language-models
    * Build a Text-to-Image Generator (from Scratch)
        * Mark Liu
        * Early 2026
        * https://www.manning.com/books/build-a-text-to-image-generator-from-scratch
    * Image Generation Models: GANs, diffusion models, and transformers
        * Vladimir Bok
        * Early 2026
        * https://www.manning.com/books/image-generation-models
    * Foundations of Large Language Models
        * Tong Xiao and Jingbo Zhu
        * June 15, 2025
        * https://arxiv.org/abs/2501.09223
    * Deep Learning with Python, Third Edition
        * Fran√ßois Chollet and Matthew Watson
        * September 2025
        * https://www.manning.com/books/deep-learning-with-python-third-edition 
    * Agentic Design Patterns: A Hands-On Guide to Building Intelligent Systems
        * Antonio Gull√≠
        * November 2025
        * https://link.springer.com/book/9783032014016 
    * Build a Reasoning Model (From Scratch)
        * Sebastian Raschka
        * Summer 2026
        * https://www.manning.com/books/build-a-reasoning-model-from-scratch
    * The Hundred-Page Language Models Book: hands-on with PyTorch
        * Andriy Burkov
        * January 15, 2025
        * https://thelmbook.com/
    * Mastering Transformers: The Journey from BERT to Large Language Models and Stable Diffusion , Second Edition
        * Sava≈ü Yƒ±ldƒ±rƒ±m and Meysam Asgari-Chenaghlu
        * June 2024
        * https://www.packtpub.com/en-us/product/mastering-transformers-9781837631506?srsltid=AfmBOorRfZJyejDNVM1gcrnKWjsD9HdcetmT_mbFmtffQinMIpHd5sml
    * AI Engineering: Building Applications with Foundation Models
        * Chip Huyen
        * December 2024
        * https://www.oreilly.com/library/view/ai-engineering/9781098166298/
    * Programming Generative AI: Large Multimodal Models with PyTorch and Hugging Face
        * Jonathan Dinu
        * July 27, 2026
        * https://a.co/d/1ihSKhg
    * Vector Databases
        * Nitin Borwankar
        * March 2026
        * https://www.oreilly.com/library/view/vector-databases/9781098177584/
    * AI Systems Performance Engineering
        * Chris Fregly
        * November 2025
        * https://www.oreilly.com/library/view/ai-systems-performance/9798341627772/
* Papers
    * Attention Is All You Need
        * Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin
        * August 2, 2023
        * https://arxiv.org/abs/1706.03762
    * Learning without training: The implicit dynamics of in-context learning
        * Benoit Dherin, Michael Munn, Hanna Mazzawi, Michael Wunder, Javier Gonzalvo
        * July 21, 2025
        * https://arxiv.org/abs/2507.16003
    * RLAD: Training LLMs to Discover Abstractions for Solving Reasoning Problems
        * Yuxiao Qu, Anikait Singh, Yoonho Lee, Amrith Setlur, Ruslan Salakhutdinov, Chelsea Finn, Aviral Kumar
        * October 2, 2025
        * https://arxiv.org/abs/2510.02263
    * Less is More: Recursive Reasoning with Tiny Networks
        * Alexia Jolicoeur-Martineau
        * October 6, 2025
        * https://arxiv.org/abs/2510.04871v1
    * Readability ‚â† Learnability: Rethinking the Role of Simplicity in Training Small Language Models
        * Ivan Lee, Taylor Berg-Kirkpatrick
        * August 25, 2025
        * https://openreview.net/forum?id=AFMGbq39bQ#discussion
    * Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models
        * Qizheng Zhang, Changran Hu, Shubhangi Upasani, Boyuan Ma, Fenglu Hong, Vamsidhar Kamanuru, Jay Rainton, Chen Wu, Mengmeng Ji, Hanchen Li, Urmish Thakker, James Zou, Kunle Olukotun
        * October 6, 2025
        * https://arxiv.org/abs/2510.04618

 

* 

Strategy

* Publishers
    * Springer 
        * https://link.springer.com/search?query=&content-type=Book&date=custom&dateFrom=2025&dateTo=2026&language=En&taxonomy=%22Artificial+Intelligence%22&facet-discipline=%22Computer+Science%22&sortBy=newestFirst
    * O'Reilly 
        * https://www.oreilly.com/search/skills/generative-ai/?type=book&rows=100&publication_date=early-release&language=en
    * Manning 
        * https://www.manning.com/catalog/data-science/machine-learning/large-language-models 
        * https://www.manning.com/catalog/data-science/deep-learning/generative-ai
    * MIT Press 
        * https://mitpress.mit.edu/textbooks/computer-science/
    * Cambridge University Press 
        * https://www.cambridge.org/us/universitypress/subjects/computer-science?options%5B%5D=New+and+forthcoming
    * Elsevier 
        * https://shop.elsevier.com/search?query=ai&type=Book&sortBy=pubDateDesc&subjectArea=physical-sciences-and-engineering/computer-science/artificial-intelligence/artificial-intelligence-general
* BookAuthority 
    * https://bookauthority.org/books/new-generative-models-books


