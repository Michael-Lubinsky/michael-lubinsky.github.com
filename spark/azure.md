1) Explain the different file formats that you are using in your project (CSV, JSON, PARQUET, Delta Table)?
2) If in source we have three columns and in destination we want to add one more column then how can you achieve this in ADF?
3) How did you implemented SCD2 in your project?
4) How to transfer data to azure synapse?
5) What is the significance of Catalyst Optimizer in PYSPARK?
6) What is schema on read and schema on write?
7) How much data you deal with on daily basic?
8) Explain the out of memory issue?
9) Query to delete the duplicate records? Explain all other types to delete duplicate records in SQL?
10) Explain Windows functions with example in SQL and PYSPARK?
11) What is serverless computing?
12) If a job is failed then how did you debug it?
13) How to optimize the slow running query?
14) What is shuffling in transformations?
15) How to use nested JSON with data bricks?
16) If data is not loading from the source in Azure Data Factory (ADF), then what will you do?
17) How many pipelines you have created?
18) PYSPARK command to read the data from a file into a data frame?
19) What is explode function in PYSPARK?
20) Write a code to read a parquet file?
21) What is YARN?
22) How did you create the Temp View?
23) Diff between DAG and LINEAGE?
24) How did you manage the pipeline from failed activity?
25) What is Partition? how spark partitions the data?
26) What is broadcast variable and broadcast joins in spark?
27) What is serialization and deserialization?
28) What is Common Data Model (CDM)?
29) What are the steps you have taken for data security in your project?
30) Diff between procedure and functions?
31) What is normalization and denormalization? what are its uses?
32) Diff between data lake and delta lake and data warehouse? 
33) What is time travel? how did you use time travel in your project?
34) How does Z Ordering works? What is the use of Z ordering?
35) How did you get the data from Rest API?
36) What is data skewness in spark?
37) Merge statement in data bricks?
38) What are the prerequisites before the migration?
39) What is logic apps? How did you used logic apps in your project?
40) Diff between coalesce and is null?


ğŸ”¹ ğ—¥ğ—¼ğ˜‚ğ—»ğ—± ğŸ­: ğ—¦ğ—¤ğ—Ÿ + ğ——ğ—®ğ˜ğ—® ğ—–ğ—®ğ˜€ğ—² ğ—¦ğ—°ğ—²ğ—»ğ—®ğ—¿ğ—¶ğ—¼ğ˜€ (ğ— ğ—²ğ—±ğ—¶ğ˜‚ğ—º)
Questions I got:

1. â€œWrite a query to get users who made purchases 3 months in a row.â€
2. â€œFind duplicate transactions but only return the latest one per user.â€
3. â€œExplain how youâ€™d optimize a query that joins 3 tables with billions of rows.â€
4. They werenâ€™t testing syntax. They were testing how I approach real data.

ğŸ”¹ ğ—¥ğ—¼ğ˜‚ğ—»ğ—± ğŸ®: ğ—£ğ˜†ğ˜ğ—µğ—¼ğ—» + ğ——ğ—®ğ˜ğ—® ğ—§ğ—¿ğ—®ğ—»ğ˜€ğ—³ğ—¼ğ—¿ğ—ºğ—®ğ˜ğ—¶ğ—¼ğ—»ğ˜€ (ğ— ğ—²ğ—±ğ—¶ğ˜‚ğ—º-ğ—›ğ—®ğ—¿ğ—±)
Questions I got:

 4. â€œWrite a Python script to detect missing data in time-series logs.â€
 5. â€œHow would you handle large file ingestion with memory constraints?â€
 6. â€œBuild a lightweight validation framework before loading to the warehouse.â€

ğŸ”¹ ğ—¥ğ—¼ğ˜‚ğ—»ğ—± ğŸ¯: ğ—¦ğ˜†ğ˜€ğ˜ğ—²ğ—º ğ——ğ—²ğ˜€ğ—¶ğ—´ğ—» ğ—³ğ—¼ğ—¿ ğ——ğ—®ğ˜ğ—® ğ—£ğ—¶ğ—½ğ—²ğ—¹ğ—¶ğ—»ğ—²ğ˜€ (ğ—›ğ—®ğ—¿ğ—±)
Questions I got:

 7. â€œDesign an end-to-end pipeline for processing clickstream data from millions of users.â€
 8. â€œHow do you make your pipeline idempotent and replay-safe?â€
 9. â€œWhat would you do if your batch job is delayed and downstream dashboards break?â€
Here, I had to think in systems, not just scripts.

ğŸ”¹ ğ—¥ğ—¼ğ˜‚ğ—»ğ—± ğŸ°: ğ—¦ğ—½ğ—®ğ—¿ğ—¸, ğ—ğ—®ğ—³ğ—¸ğ—® & ğ—¥ğ—²ğ—®ğ—¹-ğ—§ğ—¶ğ—ºğ—² ğ—£ğ—¿ğ—¼ğ—°ğ—²ğ˜€ğ˜€ğ—¶ğ—»ğ—´ (ğ—›ğ—®ğ—¿ğ—±)
Questions I got:

 10. â€œWhat causes shuffle in Spark? How can you avoid it?â€
 11. â€œHow do you manage Kafka lag in a consumer group that canâ€™t scale further?â€
 12. â€œDesign a fault-tolerant stream processing pipeline with exactly-once semantics.â€

âœ… ğ—§ğ—µğ—² ğ—§ğ˜‚ğ—¿ğ—»ğ—¶ğ—»ğ—´ ğ—£ğ—¼ğ—¶ğ—»ğ˜?
In my final interview, I was asked:
â€œWhatâ€™s one pipeline you built that failedâ€”and how did you fix it?â€


